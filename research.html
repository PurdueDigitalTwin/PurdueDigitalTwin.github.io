<!DOCTYPE HTML>
<html>
<head>
    <title>DT Lab at Purdue University</title>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no"/>
    <link rel="icon" href="assets/images/elements/icon_36_36.png">
    <link rel="stylesheet" href="assets/css/main.css"/>
</head>
<body class="is-preload">

<!-- Header -->
<header id="header">
    <div class="container">
        <h1><a href="index.html" class="icon brands fa-purdue">Purdue Digital Twin Lab</a></h1>
        <nav id="nav">
            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="people.html">People</a></li>
                <li class="current"><a href="research.html">Research</a></li>
                <li><a href="teaching.html">Teaching</a></li>
            </ul>
        </nav>
    </div>
</header>

<!-- Page Wrapper -->

<div id="page-wrapper">
    <section class="wrapper style2">
        <header class="major">
            <h2><br>2024</h2>
        </header>
    </section>

<section class="wrapper style2">
    <div class="container">
        <div class="row gtr-200">
            <div class="col-3 col-12-medium">
                <span class="image fit style3"><img src="assets/images/teaser/cover_ddt.png" alt=""/></span>
            </div>
            <div class="col-9 col-12-medium">
                <h3>Driver Digital Twin for Online Recognition of Distracted Driving Behaviors</h3>
                <p><strong><em>Yunsheng Ma, Runjia Du, Amr Abdelraouf, Kyungtae Han, Rohit Gupta, Ziran Wang</em></strong>
                    IEEE Transactions on Intelligent Vehicles
                    <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7274857">
                        [Paper]</a>
                </p>
            </div>
        </div>
    </div>

    <div class="container">
        <div class="row gtr-200">
            <div class="col-3 col-12-medium">
                <span class="image fit style3"><img src="assets/images/teaser/cover_red_tiv.png" alt=""/></span>
            </div>
            <div class="col-9 col-12-medium">
                <h3>A Survey on Multimodal Large Language Models for Autonomous Driving </h3>
                <p><strong><em>Can Cui*, Yunsheng Ma*, Xu Cao*, Wenqian Ye*, Yang Zhou, Kaizhao Liang, Jintai Chen, Juanwu Lu, Zichong Yang, Kuei-Da Liao, Tianren Gao, Erlong Li, Kun Tang, Zhipeng Cao, Tong Zhou, Ao Liu, Xinrui Yan, Shuqi Mei, Jianguo Cao, Ziran Wang, Chao Zheng</em></strong>
                    Winter Conference on Applications of Computer Vision (WACV) Workshops, 2024
                    <a href="https://openaccess.thecvf.com/content/WACV2024W/LLVM-AD/html/Cui_A_Survey_on_Multimodal_Large_Language_Models_for_Autonomous_Driving_WACVW_2024_paper.html">
                        [Paper]</a>
                </p>
            </div>
        </div>
    </div>

    <div class="container">
        <div class="row gtr-200">
            <div class="col-3 col-12-medium">
                <span class="image fit style3"><img src="assets/images/teaser/cover_das.png" alt=""/></span>
            </div>
            <div class="col-9 col-12-medium">
                <h3>Drive As You Speak: Enabling Human-Like Interaction With Large Language Models in Autonomous Vehicles </h3>
                <p><strong><em>Can Cui, Yunsheng Ma, Xu Cao, Wenqian Ye, Ziran Wang</em></strong>
                    Winter Conference on Applications of Computer Vision (WACV) Workshops, 2024
                    <a href="https://openaccess.thecvf.com/content/WACV2024W/LLVM-AD/html/Cui_Drive_As_You_Speak_Enabling_Human-Like_Interaction_With_Large_Language_WACVW_2024_paper.html">
                        [Paper]</a>
                </p>
            </div>
        </div>
    </div>

    <div class="container">
        <div class="row gtr-200">
            <div class="col-3 col-12-medium">
                <span class="image fit style3"><img src="assets/images/teaser/cover_macp.png" alt=""/></span>
            </div>
            <div class="col-9 col-12-medium">
                <h3>MACP: Efficient Model Adaptation for Cooperative Perception</h3>
                <p><strong><em>Yunsheng Ma*, Juanwu Lu*, Can Cui, Sicheng Zhao, Xu Cao, Wenqian Ye, Ziran Wang</em></strong>
                    Winter Conference on Applications of Computer Vision (WACV), 2024
                    <a href="https://openaccess.thecvf.com/content/WACV2024/html/Ma_MACP_Efficient_Model_Adaptation_for_Cooperative_Perception_WACV_2024_paper.html">
                        [Paper]</a>
                </p>
            </div>
        </div>
    </div>

</section>

<div id="page-wrapper">
    <section class="wrapper style2">
        <header class="major">
            <h2><br>2023</h2>
        </header>
    </section>

    <section class="wrapper style2">
        <div class="container">
            <div class="row gtr-200">
                <div class="col-3 col-12-medium">
                    <span class="image fit style3"><img src="assets/images/teaser/cover_red_tiv.png" alt=""/></span>
                </div>
                <div class="col-9 col-12-medium">
                    <h3>REDFormer: Radar Enlightens the Darkness of Camera Perception with Transformers</h3>
                    <p><strong><em>Can Cui, Yunsheng Ma, Juanwu Lu, Ziran Wang;</em></strong>
                        IEEE Transactions on Intelligent Vehicles
                        <a href="https://ieeexplore.ieee.org/abstract/document/10310160">
                            [Paper]</a>
                        <a href="https://github.com/PurdueDigitalTwin/REDFormer">
                                [Code]</a>
                    </p>
                </div>
            </div>
        </div>

        <!-- <div class="container">
            <div class="row gtr-200">
                <div class="col-3 col-12-medium">
                    <span class="image fit style3"><img src="assets/images/teaser/cover_red_tiv.png" alt=""/></span>
                </div>
                <div class="col-9 col-12-medium">
                    <h3>REDFormer: Radar Enlightens the Darkness of Camera Perception with Transformers</h3>
                    <p><strong><em>Can Cui, Yunsheng Ma, Juanwu Lu, Ziran Wang;</em></strong>
                        IEEE Transactions on Intelligent Vehicles
                        <a href="https://ieeexplore.ieee.org/abstract/document/10310160">
                            [Paper]</a>
                        <a href="https://github.com/PurdueDigitalTwin/REDFormer">
                                [Code]</a>
                    </p>
                </div>
            </div>
        </div> -->

<!-- 
    </section> -->


        <div class="container">
            <div class="row gtr-200">
                <div class="col-3 col-12-medium">
                    <span class="image fit style3"><img src="assets/images/teaser/cover_cemformer.png" alt=""/></span>
                </div>
                <div class="col-9 col-12-medium">
                    <h3>CEMFormer: Learning to Predict Driver Intentions from In-Cabin and External Cameras via
                        Spatial-Temporal Transformers</h3>
                    <p><strong><em>Yunsheng Ma, Wenqian Ye, Xu Cao, Amr Abdelraouf, Kyungtae Han, Rohit Gupta, Ziran
                        Wang;</em></strong>
                        IEEE International Conference on Intelligent Transportation Systems (ITSC), 2023
                        <a href="https://arxiv.org/abs/2305.07840">
                            [Paper]</a>
                    </p>
                </div>
            </div>
        </div>
        <div class="container">
            <div class="row gtr-200">
                <div class="col-3 col-12-medium">
                    <span class="image fit style3"><img src="assets/images/teaser/cover_survey-fed.png" alt=""/></span>
                </div>
                <div class="col-9 col-12-medium">
                    <h3>A survey of federated learning for connected and automated vehicles</h3>
                    <p><strong><em>Chellapandi, Vishnu Pandi, Liangqi Yuan, Stanislaw H. Zak, Ziran Wang;</em></strong>
                        IEEE International Conference on Intelligent Transportation Systems (ITSC), 2023
                        <a href="https://arxiv.org/abs/2303.10677">
                            [Paper]</a>
                    </p>
                </div>
            </div>
        </div>
        <div class="container">
            <div class="row gtr-200">
                <div class="col-3 col-12-medium">
                    <span class="image fit style3"><img src="assets/images/teaser/cover_m2dar.png" alt=""/></span>
                </div>
                <div class="col-9 col-12-medium">
                    <h3>M<sup>2</sup>DAR: Multi-View Multi-Scale Driver Action Recognition With Vision Transformer</h3>
                    <p><strong><em>Yunsheng Ma, Liangqi Yuan, Amr Abdelraouf, Kyungtae Han, Rohit Gupta, Zihao Li, Ziran
                        Wang;</em></strong>
                        Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
                        Workshops, 2023, pp. 5286-5293
                        <a href="https://openaccess.thecvf.com/content/CVPR2023W/AICity/html/Ma_M2DAR_Multi-View_Multi-Scale_Driver_Action_Recognition_With_Vision_Transformer_CVPRW_2023_paper.html">
                            [Paper]</a>
                        <a href="https://github.com/PurdueDigitalTwin/M2DAR">
                            [Code]</a>
                    </p>
                </div>
            </div>
        </div>
        <div class="container">
            <div class="row gtr-200">
                <div class="col-3 col-12-medium">
                    <span class="image fit style3"><img src="assets/images/teaser/cover_p2p.png" alt=""/></span>
                </div>
                <div class="col-9 col-12-medium">
                    <h3>Peer-to-Peer Federated Continual Learning for Naturalistic Driving Action Recognition</h3>
                    <p><strong><em>Liangqi Yuan, Yunsheng Ma, Lu Su, Ziran Wang;</em></strong>
                        Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
                        Workshops, 2023, pp. 5249-5258
                        <a href="https://openaccess.thecvf.com/content/CVPR2023W/AICity/html/Yuan_Peer-to-Peer_Federated_Continual_Learning_for_Naturalistic_Driving_Action_Recognition_CVPRW_2023_paper.html">
                            [Paper]</a>
                    </p>
                </div>
            </div>
        </div>
        <div class="container">
            <div class="row gtr-200">
                <div class="col-3 col-12-medium">
                    <span class="image fit style3"><img src="assets/images/teaser/cover_vit-dd.png" alt=""/></span>
                </div>
                <div class="col-9 col-12-medium">
                    <h3>ViT-DD: Multi-Task Vision Transformer for Semi-Supervised Driver Distraction Detection</h3>
                    <p><strong><em>Yunsheng Ma, Ziran Wang;</em></strong>
                        IEEE Intelligent Vehicles Symposium (IV), 2023
                        <a href="https://arxiv.org/abs/2209.09178">
                            [Paper]</a>
                        <a href="https://github.com/PurdueDigitalTwin/ViT-DD">
                            [Code]</a>
                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer id="footer">
        <a href="https://www.easycounter.com/">
            <img src="https://www.easycounter.com/counter.php?purduedigitaltwin" alt="stats counter"></a>
        unique visitors since July 2023.
        <p class="copyright">&copy; 2023 Purdue Digital Twin Lab</p>
    </footer>

</div>

<!-- Scripts -->
<script src="assets/js/jquery.min.js"></script>
<script src="assets/js/jquery.dropotron.min.js"></script>
<script src="assets/js/browser.min.js"></script>
<script src="assets/js/breakpoints.min.js"></script>
<script src="assets/js/util.js"></script>
<script src="assets/js/main.js"></script>

</body>
</html>